{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zkqE5-m1RV5v"
   },
   "source": [
    "### JHU-DSCI Practical Machine Learning - Peer-graded Assignment\n",
    "\n",
    "* Name: Walter Yu\n",
    "* Date: January 2021\n",
    "\n",
    "### Submission Notes\n",
    "\n",
    "1. This project is an analysis of the Human Activity Recognition [dataset][01.00].\n",
    "\n",
    "[01.00]: http://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har\n",
    "\n",
    "2. Some charts and analysis output have been commented out to minimize overall length of document. Given project scope, it was a challenge to document all work while keeping document below maximum page length.\n",
    "\n",
    "3. The course mentor [example project][01.01] and [model training example][01.02]  were referenced while developing this project to resolve issues with random forest model training times which were excessive without parallel processing.\n",
    "\n",
    "[01.01]: http://lgreski.github.io/practicalmachinelearning/\n",
    "[01.02]: https://github.com/lgreski/datasciencectacontent/blob/master/markdown/pml-randomForestPerformance.md\n",
    "\n",
    "4. The caret package was unable to be installed on my Windows installation of the Anaconda application, so project was completed using Jupyter Notebook with [Google Colab][01.03]. All files and output remain the same, but project was completed with Jupyter in lieu of R markdown.\n",
    "\n",
    "[01.03]: https://stackoverflow.com/questions/54595285/how-to-use-r-with-google-colaboratory\n",
    "\n",
    "### Methodology\n",
    "\n",
    "1. Project is organized into 3 parts: 1) data processing, 2) model training, and 3) model testing. Each part includes analysis and code of steps taken to train/test model and make predictions.\n",
    "\n",
    "2. Both train/test datasets contain 160 columns; many of them contain all null values upon visual inspection and checking for null value count within each column. Also, the assignment instructions and HAR dataset documentation indicates that exercise movement and whether they were done correctly are of primary interest. As a result, irrelevant columns and rows with excessive null values were removed from train/test datasets.\n",
    "\n",
    "3. Random forest was selected for the machine learning model since it is typically regarded as the most accurate without excessive model complexity per the course lecture videos and forum discussions.\n",
    "\n",
    "4. The parallel and doParallel packages were used to speed up model training, and the course mentor example was referenced as noted above.\n",
    "\n",
    "5. Model was trained by splitting the training dataset into train/test partitions. Results were evaluated with confusion matrices. Predictions were made with the testing dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ogCg9UaUr__F"
   },
   "source": [
    "### Data Processing\n",
    "\n",
    "Data was prepared for train/test as follows:\n",
    "\n",
    "1. Read in train and test data files with na.string option to flag null values.\n",
    "2. Review data and identify null values since their values need to be removed or imputed. The dataset was subset to remove columns which contained all zero values.\n",
    "3. Review data and identify columns with information not relevant to prediction task, e.g. user names, timestamps, etc. The dataset was subset to remove columns with only relevant data to minimize the impact on the model training/testing performance.\n",
    "4. Dataset dimension were reviewed before and after subset to verify results.\n",
    "5. Data processing steps were completed for train/test datasets.\n",
    "\n",
    "* Note: The course mentor guides for random forest modeling was referenced to setup model training. Confusion matrix was used to verify results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "id": "MRc72vYARj3b",
    "outputId": "8796e0d6-4fc6-4d6d-fb43-41f08405b2db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"train_data dimensions (all cases): \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>19622</li><li>160</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 19622\n",
       "\\item 160\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 19622\n",
       "2. 160\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 19622   160"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"test_data dimensions (all cases): \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>20</li><li>160</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 20\n",
       "\\item 160\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 20\n",
       "2. 160\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1]  20 160"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"train_data dimensions (remove null columns): \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>19622</li><li>60</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 19622\n",
       "\\item 60\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 19622\n",
       "2. 60\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 19622    60"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"train_data dimensions (remove irrelevant columns\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>19622</li><li>53</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 19622\n",
       "\\item 53\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 19622\n",
       "2. 53\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 19622    53"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"test_data dimensions (remove null columns): \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>20</li><li>60</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 20\n",
       "\\item 60\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 20\n",
       "2. 60\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 20 60"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"test_data dimensions (remove irrelevant columns\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>20</li><li>53</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 20\n",
       "\\item 53\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 20\n",
       "2. 53\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 20 53"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 01.00, final project: data processing\n",
    "\n",
    "# reference: read csv data and fill null values\n",
    "# https://stackoverflow.com/questions/6299220/access-a-url-and-read-data-with-r\n",
    "# https://stackoverflow.com/questions/25771071/r-read-csv-more-columns-than-column-names-error\n",
    "train_data = read.csv(\n",
    "    url(\"https://raw.githubusercontent.com/walteryu/jhu-ml-project/main/pml-training.csv\"),\n",
    "    na.strings = c('NA','NAN','#DIV/0!','NaN','')\n",
    ")\n",
    "print(\"train_data dimensions (all cases): \")\n",
    "dim(train_data)\n",
    "# import test dataset with same options\n",
    "test_data = read.csv(\n",
    "    url(\"https://raw.githubusercontent.com/walteryu/jhu-ml-project/main/pml-testing.csv\"),\n",
    "    na.strings = c('NA','NAN','#DIV/0!','NaN','')\n",
    ")\n",
    "print(\"test_data dimensions (all cases): \")\n",
    "dim(test_data)\n",
    "\n",
    "# subset for columns for null values\n",
    "# https://stackoverflow.com/questions/15968494/how-to-delete-columns-that-contain-only-nas/45383054\n",
    "# https://stackoverflow.com/questions/25188051/using-is-na-in-r-to-get-column-names-that-contain-na-values\n",
    "train_data = train_data[,colSums(is.na(train_data)) == 0]\n",
    "print(\"train_data dimensions (remove null columns): \")\n",
    "dim(train_data)\n",
    "# subset for columns for irrelevant columns\n",
    "train_data <- train_data[,-c(1:7)]\n",
    "print(\"train_data dimensions (remove irrelevant columns\")\n",
    "dim(train_data)\n",
    "\n",
    "# subset for columns for null values\n",
    "# https://stackoverflow.com/questions/15968494/how-to-delete-columns-that-contain-only-nas/45383054\n",
    "# https://stackoverflow.com/questions/25188051/using-is-na-in-r-to-get-column-names-that-contain-na-values\n",
    "test_data = test_data[,colSums(is.na(test_data)) == 0]\n",
    "print(\"test_data dimensions (remove null columns): \")\n",
    "dim(test_data)\n",
    "# subset for columns for irrelevant columns\n",
    "test_data <- test_data[,-c(1:7)]\n",
    "print(\"test_data dimensions (remove irrelevant columns\")\n",
    "dim(test_data)\n",
    "\n",
    "# subset first n rows to speed up training\n",
    "# print(\"train_data dimensions (before subset): \")\n",
    "# dim(train_data)\n",
    "# df_training = train_data[1:10000,]\n",
    "# print(\"train_data dimensions (after subset): \")\n",
    "# dim(df_training)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NNDFu8peDOVO"
   },
   "source": [
    "### Model Training\n",
    "\n",
    "As described in the introduction, random forest was selected for its performance capability and relevance for the prediction task. Model training was completed as follows:\n",
    "\n",
    "1. Configure parallel and doParallel package for model training.\n",
    "2. Create and configure trainControl object to run parallel process.\n",
    "3. Perform cross validation using trainControl object.\n",
    "4. Train model with random forest and stop cluster when done.\n",
    "5. Review model fit summary and confusion matrix to verify results.\n",
    "\n",
    "* Note: The course mentor guides for random forest modeling was referenced to setup model training. Confusion matrix was used to verify results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "sL16Lq0spK8r",
    "outputId": "e0674975-9672-4028-a435-fdd03aa3d8ec"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into ‘/usr/local/lib/R/site-library’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n",
      "also installing the dependencies ‘R.methodsS3’, ‘R.oo’, ‘R.utils’, ‘bitops’, ‘numDeriv’, ‘SQUAREM’, ‘httpuv’, ‘xtable’, ‘sourcetools’, ‘fastmap’, ‘R.cache’, ‘caTools’, ‘TH.data’, ‘profileModel’, ‘minqa’, ‘nloptr’, ‘statmod’, ‘RcppEigen’, ‘plotrix’, ‘lava’, ‘shiny’, ‘miniUI’, ‘styler’, ‘classInt’, ‘labelled’, ‘gplots’, ‘libcoin’, ‘matrixStats’, ‘multcomp’, ‘iterators’, ‘data.table’, ‘gower’, ‘timeDate’, ‘brglm’, ‘gtools’, ‘lme4’, ‘qvcalc’, ‘Formula’, ‘plotmo’, ‘TeachingDemos’, ‘prodlim’, ‘combinat’, ‘questionr’, ‘ROCR’, ‘mvtnorm’, ‘modeltools’, ‘strucchange’, ‘coin’, ‘zoo’, ‘sandwich’, ‘ISwR’, ‘corpcor’, ‘foreach’, ‘plyr’, ‘ModelMetrics’, ‘reshape2’, ‘recipes’, ‘pROC’, ‘BradleyTerry2’, ‘e1071’, ‘earth’, ‘fastICA’, ‘gam’, ‘ipred’, ‘kernlab’, ‘klaR’, ‘ellipse’, ‘mda’, ‘mlbench’, ‘MLmetrics’, ‘party’, ‘pls’, ‘proxy’, ‘randomForest’, ‘RANN’, ‘spls’, ‘subselect’, ‘pamr’, ‘superpc’, ‘Cubist’\n",
      "\n",
      "\n",
      "Installing package into ‘/usr/local/lib/R/site-library’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n",
      "Warning message:\n",
      "“package ‘parallel’ is a base package, and should not be updated”\n",
      "Installing package into ‘/usr/local/lib/R/site-library’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n",
      "Loading required package: lattice\n",
      "\n",
      "Loading required package: ggplot2\n",
      "\n",
      "Loading required package: foreach\n",
      "\n",
      "Loading required package: iterators\n",
      "\n",
      "Warning message in RNGkind(\"Mersenne-Twister\", \"Inversion\", \"Rounding\"):\n",
      "“non-uniform 'Rounding' sampler used”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"setting up cluster and trainControl object...\"\n",
      "[1] \"model training with random forest...\"\n",
      "[1] \"stop cluster after model training...\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Random Forest \n",
       "\n",
       "19622 samples\n",
       "   52 predictor\n",
       "    5 classes: 'A', 'B', 'C', 'D', 'E' \n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (5 fold) \n",
       "Summary of sample sizes: 15697, 15698, 15699, 15697, 15697 \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  mtry  Accuracy   Kappa    \n",
       "   2    0.9934256  0.9916836\n",
       "  27    0.9936296  0.9919415\n",
       "  52    0.9879727  0.9847847\n",
       "\n",
       "Accuracy was used to select the optimal model using the largest value.\n",
       "The final value used for the model was mtry = 27."
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 5 × 3</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>Accuracy</th><th scope=col>Kappa</th><th scope=col>Resample</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.9926115</td><td>0.9906527</td><td>Fold1</td></tr>\n",
       "\t<tr><td>0.9933724</td><td>0.9916159</td><td>Fold3</td></tr>\n",
       "\t<tr><td>0.9938838</td><td>0.9922639</td><td>Fold2</td></tr>\n",
       "\t<tr><td>0.9943949</td><td>0.9929101</td><td>Fold5</td></tr>\n",
       "\t<tr><td>0.9938854</td><td>0.9922650</td><td>Fold4</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 5 × 3\n",
       "\\begin{tabular}{lll}\n",
       " Accuracy & Kappa & Resample\\\\\n",
       " <dbl> & <dbl> & <chr>\\\\\n",
       "\\hline\n",
       "\t 0.9926115 & 0.9906527 & Fold1\\\\\n",
       "\t 0.9933724 & 0.9916159 & Fold3\\\\\n",
       "\t 0.9938838 & 0.9922639 & Fold2\\\\\n",
       "\t 0.9943949 & 0.9929101 & Fold5\\\\\n",
       "\t 0.9938854 & 0.9922650 & Fold4\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 5 × 3\n",
       "\n",
       "| Accuracy &lt;dbl&gt; | Kappa &lt;dbl&gt; | Resample &lt;chr&gt; |\n",
       "|---|---|---|\n",
       "| 0.9926115 | 0.9906527 | Fold1 |\n",
       "| 0.9933724 | 0.9916159 | Fold3 |\n",
       "| 0.9938838 | 0.9922639 | Fold2 |\n",
       "| 0.9943949 | 0.9929101 | Fold5 |\n",
       "| 0.9938854 | 0.9922650 | Fold4 |\n",
       "\n"
      ],
      "text/plain": [
       "  Accuracy  Kappa     Resample\n",
       "1 0.9926115 0.9906527 Fold1   \n",
       "2 0.9933724 0.9916159 Fold3   \n",
       "3 0.9938838 0.9922639 Fold2   \n",
       "4 0.9943949 0.9929101 Fold5   \n",
       "5 0.9938854 0.9922650 Fold4   "
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Cross-Validated (5 fold) Confusion Matrix \n",
       "\n",
       "(entries are percentual average cell counts across resamples)\n",
       " \n",
       "          Reference\n",
       "Prediction    A    B    C    D    E\n",
       "         A 28.4  0.1  0.0  0.0  0.0\n",
       "         B  0.0 19.2  0.1  0.0  0.0\n",
       "         C  0.0  0.0 17.3  0.2  0.0\n",
       "         D  0.0  0.0  0.1 16.2  0.1\n",
       "         E  0.0  0.0  0.0  0.0 18.3\n",
       "                            \n",
       " Accuracy (average) : 0.9936\n"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 02.00, final project: model training\n",
    "\n",
    "# load packages: machine learning models\n",
    "# references: course quiz and assignments\n",
    "# https://github.com/lgreski/datasciencectacontent/blob/7f88642673eeb5913459eb05bd5b58734c8f0bd5/markdown/pml-randomForestPerformance.md\n",
    "install.packages(\"caret\", dependencies = TRUE)\n",
    "install.packages(\"parallel\")\n",
    "install.packages(\"doParallel\")\n",
    "library(caret)\n",
    "library(parallel)\n",
    "library(doParallel)\n",
    "\n",
    "# set random number generation/seed\n",
    "# references: course quiz and assignments\n",
    "# https://github.com/lgreski/datasciencectacontent/blob/7f88642673eeb5913459eb05bd5b58734c8f0bd5/markdown/pml-randomForestPerformance.md\n",
    "RNGversion(\"3.5.1\")\n",
    "set.seed(3523)\n",
    "\n",
    "# set random number generation/seed\n",
    "# references:\n",
    "# class lecture slides on random forest (set 21, slide 4)\n",
    "# https://github.com/lgreski/datasciencectacontent/blob/7f88642673eeb5913459eb05bd5b58734c8f0bd5/markdown/pml-randomForestPerformance.md\n",
    "inTrain = createDataPartition(y=train_data$classe, p = 0.7, list=FALSE)\n",
    "training = train_data[ inTrain,]\n",
    "testing = train_data[-inTrain,]\n",
    "\n",
    "# configure parallel model training\n",
    "# https://github.com/lgreski/datasciencectacontent/blob/7f88642673eeb5913459eb05bd5b58734c8f0bd5/markdown/pml-randomForestPerformance.md\n",
    "print(\"setting up cluster and trainControl object...\")\n",
    "cluster <- makeCluster(detectCores() - 1)\n",
    "registerDoParallel(cluster)\n",
    "\n",
    "# create fitControl object with cross validation parameter\n",
    "# https://github.com/lgreski/datasciencectacontent/blob/7f88642673eeb5913459eb05bd5b58734c8f0bd5/markdown/pml-randomForestPerformance.md\n",
    "fitControl <- trainControl(\n",
    "    method = \"cv\",\n",
    "    number = 5,\n",
    "    allowParallel = TRUE\n",
    ")\n",
    "\n",
    "# train model with random forest\n",
    "# https://github.com/lgreski/datasciencectacontent/blob/7f88642673eeb5913459eb05bd5b58734c8f0bd5/markdown/pml-randomForestPerformance.md\n",
    "print(\"model training with random forest...\")\n",
    "fit <- train(classe ~ .,\n",
    "    method=\"rf\",\n",
    "    data=train_data,\n",
    "    trControl = fitControl\n",
    ")\n",
    "\n",
    "# shutdown parallel processing cluster\n",
    "# https://github.com/lgreski/datasciencectacontent/blob/7f88642673eeb5913459eb05bd5b58734c8f0bd5/markdown/pml-randomForestPerformance.md\n",
    "print(\"stop cluster after model training...\")\n",
    "stopCluster(cluster)\n",
    "registerDoSEQ()\n",
    "\n",
    "# evaluate results with confusion matrix\n",
    "# https://github.com/lgreski/datasciencectacontent/blob/7f88642673eeb5913459eb05bd5b58734c8f0bd5/markdown/pml-randomForestPerformance.md\n",
    "fit\n",
    "fit$resample\n",
    "confusionMatrix.train(fit)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0zO_Fk7aKNrL"
   },
   "source": [
    "### Model Testing\n",
    "\n",
    "Predictions were made on the test dataset after model training and verifying results with a confusion matrix. The dataset consisted of 20 user cases, so it was used to make predictions as follows:\n",
    "\n",
    "1. Make new predictions on test data with trained model, i.e. predict on out-of-sample data.\n",
    "2. Predictions were made on classe feature, i.e. were exercises completed correctly, etc.\n",
    "3. Output predictions to verify results, i.e. predicted value for each use case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "bscy7ASr6T-s",
    "outputId": "64d0a926-b4d2-420d-d7c0-f5c1d48edb75"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>B</li><li>A</li><li>B</li><li>A</li><li>A</li><li>E</li><li>D</li><li>B</li><li>A</li><li>A</li><li>B</li><li>C</li><li>B</li><li>A</li><li>E</li><li>E</li><li>A</li><li>B</li><li>B</li><li>B</li></ol>\n",
       "\n",
       "<details>\n",
       "\t<summary style=display:list-item;cursor:pointer>\n",
       "\t\t<strong>Levels</strong>:\n",
       "\t</summary>\n",
       "\t<style>\n",
       "\t.list-inline {list-style: none; margin:0; padding: 0}\n",
       "\t.list-inline>li {display: inline-block}\n",
       "\t.list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "\t</style>\n",
       "\t<ol class=list-inline><li>'A'</li><li>'B'</li><li>'C'</li><li>'D'</li><li>'E'</li></ol>\n",
       "</details>"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item B\n",
       "\\item A\n",
       "\\item B\n",
       "\\item A\n",
       "\\item A\n",
       "\\item E\n",
       "\\item D\n",
       "\\item B\n",
       "\\item A\n",
       "\\item A\n",
       "\\item B\n",
       "\\item C\n",
       "\\item B\n",
       "\\item A\n",
       "\\item E\n",
       "\\item E\n",
       "\\item A\n",
       "\\item B\n",
       "\\item B\n",
       "\\item B\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\emph{Levels}: \\begin{enumerate*}\n",
       "\\item 'A'\n",
       "\\item 'B'\n",
       "\\item 'C'\n",
       "\\item 'D'\n",
       "\\item 'E'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. B\n",
       "2. A\n",
       "3. B\n",
       "4. A\n",
       "5. A\n",
       "6. E\n",
       "7. D\n",
       "8. B\n",
       "9. A\n",
       "10. A\n",
       "11. B\n",
       "12. C\n",
       "13. B\n",
       "14. A\n",
       "15. E\n",
       "16. E\n",
       "17. A\n",
       "18. B\n",
       "19. B\n",
       "20. B\n",
       "\n",
       "\n",
       "\n",
       "**Levels**: 1. 'A'\n",
       "2. 'B'\n",
       "3. 'C'\n",
       "4. 'D'\n",
       "5. 'E'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] B A B A A E D B A A B C B A E E A B B B\n",
       "Levels: A B C D E"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 02.01, final project: model testing\n",
    "\n",
    "# make predictions with test data\n",
    "# reference: class lecture slides on random forest (set 21, slide 8)\n",
    "pred = predict(fit, newdata=test_data)\n",
    "# output predictions to verify results\n",
    "pred\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "jhu_08_ml_project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
